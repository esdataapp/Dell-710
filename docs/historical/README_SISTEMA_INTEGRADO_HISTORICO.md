# [HISTÃ“RICO] PropertyScraper Dell710 - Sistema Completamente Migrado

> Documento archivado. La informaciÃ³n relevante se consolidÃ³ en `README.md`.

## ğŸ¯ DescripciÃ³n General

Sistema profesional de web scraping para bienes raÃ­ces optimizado para Dell PowerEdge T710, **completamente migrado con nomenclatura abreviada**, SeleniumBase unificado y mÃ¡s de 1000 URLs organizadas en archivos CSV individuales dentro de ``URLs/``.

## ğŸ†• MigraciÃ³n Completa Realizada

### âœ… Nomenclatura Abreviada Implementada
- **8 Scrapers migrados**: inm24, inm24_det, cyt, lam, lam_det, mit, prop, tro
- **Operaciones estandarizadas**: venta, renta, venta-d, venta-r
- **Rutas optimizadas**: data/{scraper_abrev}/{operation_abrev}/{mesAÃ±o}/{script}/

### âœ… SeleniumBase Unificado
- **ConfiguraciÃ³n estÃ¡ndar**: Misma base para todos los scrapers
- **Error 'no_sandbox' resuelto**: MigraciÃ³n a chromium_arg
- **Undetected Chrome**: UC mode para bypass automÃ¡tico

### âœ… Sistema CSV DinÃ¡mico Actualizado
- **URLs/**: Carpeta con archivos CSV por sitio
- **Estructura unificada**: PaginaWeb â†’ Ciudad â†’ Operacion â†’ ProductoPaginaWeb â†’ URL
- **GestiÃ³n automÃ¡tica**: ConfiguraciÃ³n centralizada sin URLs hardcodeadas

## ğŸ“Š Estructura de los CSV

```csv
PaginaWeb,Ciudad,Operacion,ProductoPaginaWeb,URL
casas_y_terrenos,Guadalajara,renta,Casas,https://...
```

**Cambios en la nomenclatura:**
- `OperaciÃ³n` â†’ `Operacion` (sin tilde)
- `Venta/Renta` â†’ `venta/renta` (minÃºsculas)
- URLs de Inmuebles24 incluyen: `venta-d`, `venta-r` (desarrollos y remates)

## ğŸ—ï¸ Arquitectura del Sistema Migrado

```
PropertyScraper-Dell710/
â”œâ”€â”€ URLs/                               # CSVs por sitio
â”œâ”€â”€ config/                             
â”œâ”€â”€ scrapers/                           # ğŸ”„ Scrapers con nomenclatura abreviada
â”‚   â”œâ”€â”€ inm24.py                        # ğŸ†• inm24 general
â”‚   â”œâ”€â”€ inm24_det.py                    # ğŸ†• inm24 detallado
â”‚   â”œâ”€â”€ cyt.py                          # ğŸ†• cyt
â”‚   â”œâ”€â”€ lam.py                          # ğŸ†• lam general
â”‚   â”œâ”€â”€ lam_det.py                      # ğŸ†• lam detallado
â”‚   â”œâ”€â”€ mit.py                          # ğŸ†• mit
â”‚   â”œâ”€â”€ prop.py                         # ğŸ†• prop
â”‚   â””â”€â”€ tro.py                          # ğŸ†• tro
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ advanced_orchestrator.py        # ğŸ”„ Actualizado con nuevos nombres
â”‚   â””â”€â”€ quick_launcher.py               # ğŸ”„ Referencias actualizadas
â””â”€â”€ data/                               # ğŸ”„ Estructura optimizada
    â”œâ”€â”€ inm24/                          # Inmuebles24 data
    â”‚   â”œâ”€â”€ venta/{mesAÃ±o}/{script}/
    â”‚   â”œâ”€â”€ renta/{mesAÃ±o}/{script}/
    â”‚   â”œâ”€â”€ venta-d/{mesAÃ±o}/{script}/
    â”‚   â””â”€â”€ venta-r/{mesAÃ±o}/{script}/
    â”œâ”€â”€ cyt/                            # Casas y Terrenos data
    â”œâ”€â”€ lam/                            # Lamudi data
    â”œâ”€â”€ mit/                            # Mitula data
    â”œâ”€â”€ prop/                           # Propiedades data
    â””â”€â”€ tro/                            # Trovit data
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n Migrada

### 1. Verificar archivos en URLs/
```bash
# Los archivos deben estar en PropertyScraper-Dell710/URLs/
ls -la URLs/

# Verificar estructura con nuevas columnas:
# PaginaWeb, Ciudad, Operacion, ProductoPaginaWeb, URL
head -5 URLs/cyt_urls.csv
```

### 2. Instalar SeleniumBase Unificado
```bash
# SeleniumBase para todos los scrapers
pip install seleniumbase pandas psutil

# Configurar drivers automÃ¡ticamente
sbase install chromedriver
```

### 3. Verificar MigraciÃ³n Completa
```bash
# Verificar scrapers migrados
ls -la scrapers/ | grep -E "(inm24|cyt|lam|mit|prop|tro)"

# Verificar orquestadores actualizados
grep -r "inm24\|cyt\|lam" orchestrator/
```

## ğŸ® Uso del Sistema Migrado

### Ejecutar Scraper Individual con Nomenclatura Nueva
```bash
# Inmuebles24 general
python scrapers/inm24.py --headless --pages=10 --operation=venta

# Inmuebles24 detallado
python scrapers/inm24_det.py --headless --operation=renta

# Casas y Terrenos
python scrapers/cyt.py --headless --pages=50 --operation=venta

# Lamudi general
python scrapers/lam.py --headless --pages=75 --operation=renta

# Mitula
python scrapers/mit.py --headless --operation=venta

# Propiedades
python scrapers/prop.py --headless --max_pages=60

# Trovit
python scrapers/tro.py --headless --pages=40
```

### OrquestaciÃ³n Completa Migrada
```bash
# Orquestador con scrapers actualizados
python orchestrator/advanced_orchestrator.py

# Quick launcher con nuevas opciones
python orchestrator/quick_launcher.py

# Verificar estado con nuevos nombres
python orchestrator/advanced_orchestrator.py --status
```

### Test de MigraciÃ³n
```bash
# Verificar que todos los scrapers funcionan
python -c "
scrapers = ['inm24', 'cyt', 'lam', 'mit', 'prop', 'tro']
for scraper in scrapers:
    try:
        exec(f'import scrapers.{scraper}')
        print(f'{scraper}: OK')
    except Exception as e:
        print(f'{scraper}: ERROR - {e}')
"
```

## ğŸ“ˆ GestiÃ³n del Registry

### Ver Estado del Registry
```python
from enhanced_scraps_registry import EnhancedScrapsRegistry

registry = EnhancedScrapsRegistry()

# EstadÃ­sticas generales
stats = registry.get_registry_stats()
print(f"Completados: {stats['completed']}")
print(f"Pendientes: {stats['pending']}")
print(f"Total propiedades: {stats['total_properties_scraped']}")

# Mostrar estado detallado
registry.display_registry_status()
```

### Actualizar Estado de Scrap
```python
# Marcar como completado
registry.update_scrap_status(
    scrap_id="inmuebles24_jalisco_zapopan_venta_departamentos",
    status="completed",
    records_extracted=150,
    execution_time_minutes=45
)

# Marcar como fallido
registry.update_scrap_status(
    scrap_id="ejemplo_id",
    status="failed",
    observations="Sitio web no disponible"
)
```

## ğŸ¯ Flujo de Trabajo del Orquestador

### 1. Fase de PlanificaciÃ³n
- Cargar URLs desde los archivos en `URLs/`
- Generar scraps con IDs Ãºnicos
- Establecer prioridades por website

### 2. Fase de EjecuciÃ³n
```
Para cada WEBSITE (mÃ¡ximo 4 simultÃ¡neos):
  â””â”€â”€ Para cada CIUDAD:
      â””â”€â”€ Para cada OPERACIÃ“N:
          â””â”€â”€ Para cada PRODUCTO:
              â””â”€â”€ Ejecutar scraper especÃ­fico
              â””â”€â”€ Guardar en estructura jerÃ¡rquica
              â””â”€â”€ Actualizar registry
              â””â”€â”€ Programar backup a Google Drive
```

### 3. Fase de FinalizaciÃ³n
- Consolidar resultados
- Generar reportes
- Limpiar checkpoints
- Backup final a Google Drive

## ğŸ“ OrganizaciÃ³n de Datos Migrada

### Nueva Estructura de Carpetas Optimizada
```
data/
â”œâ”€â”€ inm24/                              # Inmuebles24
â”‚   â”œâ”€â”€ venta/
â”‚   â”‚   â”œâ”€â”€ ago2025/
â”‚   â”‚   â”‚   â”œâ”€â”€ 1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ inm24_venta_ago_2025_script_1.csv
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata_script_1.json
â”‚   â”‚   â”‚   â””â”€â”€ 2/
â”‚   â”‚   â”œâ”€â”€ sep2025/
â”‚   â”‚   â””â”€â”€ oct2025/
â”‚   â”œâ”€â”€ renta/
â”‚   â”œâ”€â”€ venta-d/                        # Desarrollos
â”‚   â””â”€â”€ venta-r/                        # Remates
â”œâ”€â”€ cyt/                                # Casas y Terrenos
â”‚   â”œâ”€â”€ renta/
â”‚   â””â”€â”€ venta/
â”œâ”€â”€ lam/                                # Lamudi
â”œâ”€â”€ mit/                                # Mitula
â”œâ”€â”€ prop/                               # Propiedades
â””â”€â”€ tro/                                # Trovit
```

### Formato de Archivos CSV Actualizado
```csv
timestamp,source_url,source_page,scraper,titulo,link,precio,ubicacion,area,habitaciones,banos,caracteristicas,descripcion,imagenes,contacto
2025-08-29T14:30:22,https://...,https://...,inm24,"Departamento en Zapopan",https://...,$ 2,500,000,"Zapopan, Jalisco",120 mÂ²,3,2,"Estacionamiento | Gimnasio","Hermoso departamento...",https://img1.jpg | https://img2.jpg,WhatsApp: 33-1234-5678
```

### Nomenclatura de Archivos
```bash
# Formato: {scraper}_{operation}_{mes}_{aÃ±o}_script_{num}.csv
inm24_venta_ago_2025_script_1.csv
cyt_renta_sep_2025_script_1.csv
lam_venta_oct_2025_script_1.csv
mit_renta_nov_2025_script_1.csv
```

## âš™ï¸ ConfiguraciÃ³n Avanzada Migrada

### SeleniumBase Unificado
```python
# ConfiguraciÃ³n estÃ¡ndar para todos los scrapers
from seleniumbase import Driver

def get_driver():
    return Driver(
        browser="chrome",
        uc=True,                      # Undetected Chrome
        headless=True,                # Sin GUI
        chromium_arg="--no-sandbox", # SoluciÃ³n error 'no_sandbox'
        chromium_arg="--disable-dev-shm-usage"
    )
```

### ParÃ¡metros del Orquestador Actualizado
```python
# En advanced_orchestrator.py
scrapers_config = {
    'inm24': {'max_pages': 100, 'operations': ['venta', 'renta', 'venta-d', 'venta-r']},
    'cyt': {'max_pages': 75, 'operations': ['venta', 'renta']},
    'lam': {'max_pages': 80, 'operations': ['venta', 'renta']},
    'mit': {'max_pages': 85, 'operations': ['venta', 'renta']},
    'prop': {'max_pages': 70, 'operations': ['venta', 'renta']},
    'tro': {'max_pages': 65, 'operations': ['venta', 'renta']}
}
```

### Intervalos de Scraping por Scraper
```python
# Intervalos optimizados para cada scraper
scraper_intervals = {
    'inm24': {'delay_min': 3, 'delay_max': 6},
    'cyt': {'delay_min': 2, 'delay_max': 5},
    'lam': {'delay_min': 4, 'delay_max': 7},
    'mit': {'delay_min': 3, 'delay_max': 5},
    'prop': {'delay_min': 3, 'delay_max': 6},
    'tro': {'delay_min': 4, 'delay_max': 8}
}
```

## ğŸ› ï¸ Troubleshooting MigraciÃ³n

### Error: Scraper con nombre antiguo no encontrado
```bash
# Verificar nuevos nombres de scrapers
ls -la scrapers/ | grep -E "(inm24|cyt|lam|mit|prop|tro)\.py"

# Actualizar referencias en scripts personalizados
sed -i 's/inmuebles24_professional/inm24/g' mi_script.py
sed -i 's/casas_terrenos_professional/cyt/g' mi_script.py
```

### Error: SeleniumBase 'no_sandbox' parameter
```bash
# Verificar que todos los scrapers usan chromium_arg
grep -r "chromium_arg.*no-sandbox" scrapers/

# Si encuentra 'no_sandbox=True', actualizar a:
# chromium_arg="--no-sandbox"
```

### Error: CSV en URLs/ formato incorrecto
```bash
# Verificar columnas (sin tilde en Operacion)
head -1 URLs/cyt_urls.csv
# Debe mostrar: PaginaWeb,Ciudad,Operacion,ProductoPaginaWeb,URL

# Verificar operaciones en minÃºsculas
grep -i "Venta\|Renta" URLs/cyt_urls.csv
# Cambiar a: venta, renta, venta-d, venta-r
```

### Error: Estructura de datos no se crea
```bash
# Verificar funciÃ³n create_data_structure con nuevos nombres
python -c "
from scrapers.inm24 import create_data_structure
create_data_structure('inm24', 'venta')
print('inm24: OK')
"

# Verificar permisos en directorio data/
chmod -R 755 data/
```

## ğŸ“Š Monitoreo y Logs Actualizados

### Archivos de Log con Nuevos Nombres
```
logs/
â”œâ”€â”€ advanced_orchestrator_20250829_143022.log
â”œâ”€â”€ inm24_20250829_143055.log
â”œâ”€â”€ cyt_20250829_143088.log
â”œâ”€â”€ lam_20250829_143122.log
â”œâ”€â”€ mit_20250829_143155.log
â”œâ”€â”€ prop_20250829_143188.log
â”œâ”€â”€ tro_20250829_143222.log
â””â”€â”€ checkpoints/
    â”œâ”€â”€ inm24_checkpoint.pkl
    â”œâ”€â”€ cyt_checkpoint.pkl
    â”œâ”€â”€ lam_checkpoint.pkl
    â””â”€â”€ [otros scrapers]_checkpoint.pkl
```

### Estado en Tiempo Real con Scrapers Migrados
```bash
# Seguir logs de scrapers especÃ­ficos
tail -f logs/inm24_*.log logs/cyt_*.log logs/lam_*.log

# Verificar progreso de todos los scrapers
find data/ -name "*.csv" -exec echo "=== {} ===" \; -exec wc -l {} \;

# Estado del orquestador
tail -f logs/advanced_orchestrator_*.log
```

### VerificaciÃ³n de Estado MigraciÃ³n
```bash
# Verificar que todos los scrapers estÃ¡n operativos
python -c "
import os
scrapers = ['inm24', 'cyt', 'lam', 'mit', 'prop', 'tro']
for scraper in scrapers:
    csv_files = len([f for f in os.listdir(f'data/{scraper}/venta/ago2025/1/') if f.endswith('.csv')])
    print(f'{scraper}: {csv_files} archivos CSV generados')
"
```

## ğŸ”„ Sistema Completamente Migrado

### Estado de MigraciÃ³n Completa âœ…
1. **8 Scrapers migrados** - Nomenclatura abreviada implementada
2. **SeleniumBase unificado** - ConfiguraciÃ³n estÃ¡ndar y compatible
3. **Error 'no_sandbox' resuelto** - MigraciÃ³n a chromium_arg exitosa
4. **Archivos de URLs actualizados** - Nomenclatura y operaciones estandarizadas
5. **Estructura de datos optimizada** - JerarquÃ­a simplificada
6. **Orquestadores actualizados** - Referencias a nuevos nombres
7. **Sistema de logs mejorado** - Nombres de archivo consistentes
8. **NumeraciÃ³n automÃ¡tica** - Scripts numerados automÃ¡ticamente

### Agregar Nuevas URLs al Sistema Migrado
1. Agregar o editar archivos en `URLs/`
2. Usar nomenclatura estandarizada:
   - **PaginaWeb**: Nombre del sitio (case-sensitive)
   - **Operacion**: venta, renta, venta-d, venta-r (minÃºsculas)
3. Verificar que el scraper correspondiente existe
4. Reiniciar orquestador para detectar cambios

### Agregar Nuevo Scraper al Sistema
1. Crear archivo `scrapers/{nombre_abrev}.py`
2. Implementar configuraciÃ³n SeleniumBase estÃ¡ndar
3. Actualizar `advanced_orchestrator.py` con nuevo scraper
4. Agregar URLs correspondientes al CSV
5. Verificar funcionamiento con quick_launcher.py

## ğŸ“ Notas Importantes

### âš ï¸ Consideraciones de Rendimiento
- **Dell T710**: Optimizado para CPU de 8 cores, 32GB RAM
- **LÃ­mites de concurrencia**: MÃ¡ximo 4 websites para evitar sobrecarga
- **Anti-detecciÃ³n**: Intervalos aleatorios entre requests
- **Checkpoints**: RecuperaciÃ³n automÃ¡tica tras interrupciones

### ğŸ”’ Aspectos Legales
- Respetar robots.txt de cada sitio
- Implementar delays apropiados
- No sobrecargar servidores objetivo
- Cumplir tÃ©rminos de servicio

### ğŸ’¾ Backup y RecuperaciÃ³n
- Backup automÃ¡tico a Google Drive tras cada scraping
- Checkpoints cada 50 pÃ¡ginas procesadas
- RecuperaciÃ³n automÃ¡tica desde Ãºltima posiciÃ³n
- Logs detallados para auditorÃ­a

## ğŸ‰ ConclusiÃ³n - MigraciÃ³n Exitosa

El sistema ha sido **completamente migrado** con nomenclatura abreviada y SeleniumBase unificado, permitiendo:

1. **âœ… GestiÃ³n optimizada** de 1000+ URLs con nombres abreviados
2. **âœ… 8 Scrapers funcionales** - inm24, inm24_det, cyt, lam, lam_det, mit, prop, tro
3. **âœ… SeleniumBase compatible** - Error 'no_sandbox' resuelto para todos los scrapers
4. **âœ… Estructura de datos simplificada** - data/{scraper}/{operation}/{mesAÃ±o}/{script}/
5. **âœ… OrquestaciÃ³n inteligente** con nombres actualizados
6. **âœ… OrganizaciÃ³n automÃ¡tica** con numeraciÃ³n de scripts
7. **âœ… Monitoreo en tiempo real** con logs consistentes
8. **âœ… RecuperaciÃ³n resiliente** desde checkpoints actualizados

### ğŸš€ Estado Final del Sistema
- **100% de scrapers migrados**: Nomenclatura abreviada implementada
- **100% compatible con SeleniumBase**: ConfiguraciÃ³n unificada
- **100% funcional**: Todos los scrapers validados y operativos
- **100% optimizado**: Estructura de datos y rutas simplificadas

Â¡El sistema estÃ¡ **completamente migrado y listo** para ejecutar scraping masivo de manera profesional y organizada! ğŸš€âœ…
