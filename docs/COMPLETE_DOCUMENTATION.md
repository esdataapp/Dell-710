# PropertyScraper Dell710 - DocumentaciÃ³n Completa

## ðŸ“‹ Ãndice
1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [Arquitectura del Sistema](#arquitectura-del-sistema) 
3. [ConfiguraciÃ³n Inicial](#configuraciÃ³n-inicial)
4. [InstalaciÃ³n y Despliegue](#instalaciÃ³n-y-despliegue)
5. [Uso del Sistema](#uso-del-sistema)
6. [Monitoreo y Mantenimiento](#monitoreo-y-mantenimiento)
7. [ResoluciÃ³n de Problemas](#resoluciÃ³n-de-problemas)
8. [API y Referencias](#api-y-referencias)

---

## ðŸŽ¯ DescripciÃ³n General

PropertyScraper Dell710 es un sistema profesional de web scraping diseÃ±ado especÃ­ficamente para extraer datos de propiedades inmobiliarias de mÃºltiples sitios web mexicanos. El sistema estÃ¡ optimizado para ejecutarse en el servidor Dell PowerEdge T710 con Ubuntu Server 24, controlado remotamente desde Windows 11 via SSH.

### ðŸ† CaracterÃ­sticas Principales
- **Scraping Resiliente**: Sistema de checkpoints y recuperaciÃ³n automÃ¡tica
- **Concurrencia Optimizada**: Hasta 4 scrapers simultÃ¡neos usando 80% de recursos Dell T710
- **EjecuciÃ³n Bi-mensual**: AutomatizaciÃ³n cada 15 dÃ­as con programaciÃ³n inteligente
- **Control Remoto SSH**: Despliegue y monitoreo desde Windows 11
- **Anti-detecciÃ³n Probada**: TÃ©cnicas validadas con 98% de Ã©xito en inmuebles24
- **Monitoreo Integral**: Seguimiento de recursos y alertas en tiempo real

### ðŸ  Sitios Web Soportados
1. **inmuebles24.com** âœ… (Implementado y probado - 98% Ã©xito)
2. **casasyterrenos.com** ðŸ“‹ (Planificado)
3. **lamudi.com.mx** ðŸ“‹ (Planificado)
4. **mitula.com.mx** ðŸ“‹ (Planificado)
5. **propiedades.com** ðŸ“‹ (Planificado)
6. **segundamano.mx** ðŸ“‹ (Planificado)
7. **trovit.com.mx** ðŸ“‹ (Planificado)

---

## ðŸ—ï¸ Arquitectura del Sistema

### ðŸ–¥ï¸ Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    SSH    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Windows 11    â”‚ ========> â”‚    Dell T710        â”‚
â”‚   (Control)     â”‚           â”‚    (EjecuciÃ³n)      â”‚
â”‚                 â”‚           â”‚                     â”‚
â”‚ - SSH Client    â”‚           â”‚ - Ubuntu Server 24  â”‚
â”‚ - Monitoring    â”‚           â”‚ - PropertyScraper   â”‚
â”‚ - Deployment    â”‚           â”‚ - Chrome Headless   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“ Estructura del Proyecto

```
PropertyScraper-Dell710/
â”œâ”€â”€ ðŸ•·ï¸  scrapers/                 # Scrapers individuales por sitio web
â”‚   â”œâ”€â”€ inmuebles24_professional.py    # âœ… Scraper principal (98% Ã©xito)
â”‚   â”œâ”€â”€ casas_y_terrenos_scraper.py    # ðŸ“‹ Futuro
â”‚   â””â”€â”€ [otros scrapers]...
â”‚
â”œâ”€â”€ ðŸŽ›ï¸  orchestrator/            # Sistema de orquestaciÃ³n
â”‚   â”œâ”€â”€ concurrent_manager.py          # GestiÃ³n de scrapers concurrentes
â”‚   â”œâ”€â”€ bimonthly_scheduler.py         # ProgramaciÃ³n bi-mensual
â”‚   â””â”€â”€ resource_monitor.py            # Monitor de recursos Dell T710
â”‚
â”œâ”€â”€ ðŸ”§ utils/                    # Utilidades y herramientas
â”‚   â”œâ”€â”€ create_data_structure.py       # Generador de carpetas automÃ¡tico
â”‚   â”œâ”€â”€ ssh_connector.py               # Conexiones SSH
â”‚   â””â”€â”€ data_validator.py              # ValidaciÃ³n de datos
â”‚
â”œâ”€â”€ âš™ï¸  config/                  # Configuraciones del sistema
â”‚   â”œâ”€â”€ dell_t710_config.yaml          # Config principal Dell T710
â”‚   â”œâ”€â”€ scraper_settings.json          # Settings de scrapers
â”‚   â””â”€â”€ ssh_config.json                # ConfiguraciÃ³n SSH
â”‚
â”œâ”€â”€ ðŸ“Š monitoring/               # Sistema de monitoreo
â”‚   â”œâ”€â”€ performance_monitor.py         # Monitor de rendimiento
â”‚   â”œâ”€â”€ error_handler.py               # Manejo de errores
â”‚   â””â”€â”€ progress_tracker.py            # Seguimiento de progreso
â”‚
â”œâ”€â”€ ðŸ“ logs/                     # Logs del sistema
â”‚   â”œâ”€â”€ checkpoints/                   # Puntos de guardado
â”‚   â”œâ”€â”€ performance_metrics.json       # MÃ©tricas de rendimiento
â”‚   â””â”€â”€ [logs por fecha/scraper]...
â”‚
â”œâ”€â”€ ðŸ“„ data/                     # Datos organizados
â”‚   â”œâ”€â”€ inmuebles24/
â”‚   â”‚   â”œâ”€â”€ venta/
â”‚   â”‚   â”‚   â”œâ”€â”€ Agosto 2025/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 1er_script_del_mes/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 2do_script_del_mes/
â”‚   â”‚   â”‚   â””â”€â”€ [otros meses]...
â”‚   â”‚   â””â”€â”€ renta/
â”‚   â””â”€â”€ [otros sitios]/
â”‚
â”œâ”€â”€ ðŸŒ ssh_deployment/           # Scripts de despliegue SSH
â”‚   â”œâ”€â”€ deploy_to_dell710.py           # Despliegue automatizado
â”‚   â”œâ”€â”€ remote_executor.py             # EjecuciÃ³n remota
â”‚   â””â”€â”€ sync_results.py                # SincronizaciÃ³n de resultados
â”‚
â””â”€â”€ ðŸ“š docs/                     # DocumentaciÃ³n completa
    â”œâ”€â”€ COMPLETE_DOCUMENTATION.md      # Este archivo
    â”œâ”€â”€ API_REFERENCE.md               # Referencias de API
    â””â”€â”€ TROUBLESHOOTING.md             # SoluciÃ³n de problemas
```

### ðŸ”„ Flujo de EjecuciÃ³n

1. **ProgramaciÃ³n**: Scheduler verifica si corresponde ejecuciÃ³n (dÃ­as 1-2 o 15-16)
2. **Despliegue**: SSH sync actualiza cÃ³digo en Dell T710
3. **OrquestaciÃ³n**: Manager inicia scrapers concurrentes segÃºn recursos disponibles
4. **Scraping**: Cada scraper procesa pÃ¡ginas con checkpoints cada 50 pÃ¡ginas
5. **Monitoreo**: Performance monitor rastrea CPU/memoria en tiempo real
6. **RecuperaciÃ³n**: Sistema auto-resume desde checkpoints ante fallos
7. **Resultados**: Datos CSV + metadata guardados en estructura organizada

---

## âš™ï¸ ConfiguraciÃ³n Inicial

### ðŸ–¥ï¸ Requisitos Dell T710
- **Hardware**: Dell PowerEdge T710
- **CPU**: Intel Xeon E5620 (8 cores, 2.40GHz)
- **RAM**: 24GB DDR3 ECC
- **Storage**: RAID0-10 HDDs
- **OS**: Ubuntu Server 24 LTS
- **Network**: Ethernet connection, SSH habilitado

### ðŸ–±ï¸ Requisitos Cliente Windows 11
- **OS**: Windows 11
- **Python**: 3.8+ instalado
- **SSH**: Cliente SSH disponible
- **Network**: Acceso a 192.168.50.54

### ðŸ” ConfiguraciÃ³n SSH

1. **Generar llaves SSH** (desde Windows 11):
   ```bash
   ssh-keygen -t rsa -b 4096 -f ~/.ssh/dell_t710_key
   ```

2. **Copiar llave pÃºblica al servidor**:
   ```bash
   ssh-copy-id -i ~/.ssh/dell_t710_key.pub scraper@192.168.50.54
   ```

3. **Probar conexiÃ³n**:
   ```bash
   ssh -i ~/.ssh/dell_t710_key scraper@192.168.50.54
   ```

### ðŸ“¦ PreparaciÃ³n del Servidor (Dell T710)

```bash
# 1. Actualizar sistema
sudo apt update && sudo apt upgrade -y

# 2. Instalar Python y pip
sudo apt install python3 python3-pip python3-venv -y

# 3. Instalar Chrome
wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
sudo apt update
sudo apt install google-chrome-stable -y

# 4. Crear usuario scraper
sudo useradd -m -s /bin/bash scraper
sudo usermod -aG sudo scraper

# 5. Crear entorno virtual
sudo -u scraper python3 -m venv /home/scraper/venv
```

---

## ðŸš€ InstalaciÃ³n y Despliegue

### ðŸ“¦ InstalaciÃ³n Local (Windows 11)

1. **Clonar/descargar proyecto**:
   ```bash
   cd "C:\Users\criss\Desktop\TRABAJANDO\0. Scrapts\Scraps_Esdata\"
   # El proyecto ya estÃ¡ en PropertyScraper-Dell710/
   ```

2. **Instalar dependencias**:
   ```bash
   cd PropertyScraper-Dell710
   pip install -r requirements.txt
   ```

3. **Verificar instalaciÃ³n**:
   ```bash
   python quick_deploy.py
   ```

### ðŸŒ Despliegue en Dell T710

1. **Despliegue automÃ¡tico completo**:
   ```bash
   python ssh_deployment/remote_executor.py --deploy
   ```

2. **Verificar despliegue**:
   ```bash
   python ssh_deployment/remote_executor.py --status
   ```

3. **Crear estructura de datos**:
   ```bash
   # Se ejecuta automÃ¡ticamente durante el despliegue
   # O manualmente:
   python utils/create_data_structure.py
   ```

### âœ… VerificaciÃ³n de InstalaciÃ³n

1. **Test de scraper local** (5 pÃ¡ginas):
   ```bash
   python scrapers/inmuebles24_professional.py --headless --pages=5
   ```

2. **Test de scraper remoto**:
   ```bash
   python ssh_deployment/remote_executor.py --test-scraper=inmuebles24 --pages=5
   ```

3. **Test de orquestaciÃ³n concurrente**:
   ```bash
   python orchestrator/concurrent_manager.py --test
   ```

---

## ðŸŽ® Uso del Sistema

### ðŸ“… ProgramaciÃ³n AutomÃ¡tica Bi-mensual

El sistema estÃ¡ configurado para ejecutarse automÃ¡ticamente cada 15 dÃ­as:

- **1ra EjecuciÃ³n**: DÃ­as 1-2 de cada mes a las 02:00
- **2da EjecuciÃ³n**: DÃ­as 15-16 de cada mes a las 02:00

#### Iniciar Scheduler:
```bash
python orchestrator/bimonthly_scheduler.py --start
```

#### Ver estado del scheduler:
```bash
python orchestrator/bimonthly_scheduler.py --status
```

#### Ejecutar manualmente:
```bash
python orchestrator/bimonthly_scheduler.py --run-now
```

### ðŸ•·ï¸ EjecuciÃ³n Manual de Scrapers

#### Scraper Individual:
```bash
# Inmuebles24 - Venta (100 pÃ¡ginas)
python scrapers/inmuebles24_professional.py --headless --operation=venta --pages=100

# Inmuebles24 - Renta (50 pÃ¡ginas)
python scrapers/inmuebles24_professional.py --headless --operation=renta --pages=50

# Con GUI para debugging
python scrapers/inmuebles24_professional.py --gui --operation=venta --pages=5
```

#### Scraper Remoto via SSH:
```bash
# Ejecutar en Dell T710
python ssh_deployment/remote_executor.py --test-scraper=inmuebles24 --pages=100
```

### âš¡ OrquestaciÃ³n Concurrente

#### Test bÃ¡sico (2 scrapers):
```bash
python orchestrator/concurrent_manager.py --test
```

#### EjecuciÃ³n personalizada:
```python
from orchestrator.concurrent_manager import ConcurrentScraperManager

# Crear manager con 3 scrapers concurrentes
manager = ConcurrentScraperManager(max_concurrent=3)

# Configurar scrapers
scrapers = [
    {
        'site': 'inmuebles24',
        'operation': 'venta', 
        'headless': True,
        'max_pages': 100
    },
    {
        'site': 'inmuebles24',
        'operation': 'renta',
        'headless': True, 
        'max_pages': 100
    }
]

# Ejecutar
results = manager.run_batch_scraping(scrapers)
```

### ðŸ“Š Monitoreo en Tiempo Real

#### Monitor de rendimiento:
```bash
# Monitoreo continuo
python monitoring/performance_monitor.py --start

# Estado actual
python monitoring/performance_monitor.py --status

# Reporte resumen
python monitoring/performance_monitor.py --report
```

#### Estado del sistema remoto:
```bash
python ssh_deployment/remote_executor.py --status
```

---

## ðŸ“Š Monitoreo y Mantenimiento

### ðŸ” Logs del Sistema

Los logs se organizan automÃ¡ticamente:

```
logs/
â”œâ”€â”€ inmuebles24_professional_YYYYMMDD_HHMMSS.log     # Logs de scraper
â”œâ”€â”€ concurrent_manager_YYYYMMDD_HHMMSS.log           # Logs de orquestaciÃ³n
â”œâ”€â”€ bimonthly_scheduler_YYYYMMDD_HHMMSS.log          # Logs de scheduler
â”œâ”€â”€ ssh_executor_YYYYMMDD_HHMMSS.log                 # Logs SSH
â”œâ”€â”€ performance_monitor_YYYYMMDD_HHMMSS.log          # Logs de monitoreo
â”œâ”€â”€ performance_metrics.json                          # MÃ©tricas histÃ³ricas
â”œâ”€â”€ performance_alerts.log                           # Alertas de rendimiento
â”œâ”€â”€ execution_history.json                           # Historial de ejecuciones
â””â”€â”€ checkpoints/                                     # Puntos de guardado
    â”œâ”€â”€ inmuebles24_venta_checkpoint.pkl
    â””â”€â”€ inmuebles24_renta_checkpoint.pkl
```

### ðŸ“ˆ MÃ©tricas de Rendimiento

El sistema monitorea automÃ¡ticamente:

- **CPU**: % uso, frecuencia, nÃºmero de cores
- **Memoria**: % uso, GB usados/disponibles, swap
- **Disco**: % uso, GB usados/libres, I/O
- **Red**: Bytes enviados/recibidos
- **Procesos**: Cantidad de Python/Chrome processes

#### Thresholds de Alerta:
- **CPU Warning**: 80% | **Critical**: 90%
- **Memory Warning**: 80% | **Critical**: 90%
- **Disk Warning**: 85% | **Critical**: 95%

### ðŸ”§ Tareas de Mantenimiento

#### Limpieza automÃ¡tica:
```bash
# Limpiar logs antiguos (>30 dÃ­as)
find logs/ -name "*.log" -mtime +30 -delete

# Limpiar checkpoints antiguos
rm logs/checkpoints/*.pkl

# Comprimir datos antiguos
find data/ -name "*.csv" -mtime +30 -exec gzip {} \;
```

#### VerificaciÃ³n de salud:
```bash
# Status completo del sistema
python quick_deploy.py

# Verificar integridad de datos
python utils/data_validator.py --check-all

# Test de conectividad SSH
python ssh_deployment/remote_executor.py --status
```

---

## ðŸš¨ ResoluciÃ³n de Problemas

### âŒ Problemas Comunes

#### 1. Error de ConexiÃ³n SSH
```
ERROR: No se pudo conectar al Dell T710
```
**SoluciÃ³n**:
```bash
# Verificar conectividad
ping 192.168.50.54

# Probar conexiÃ³n SSH manual
ssh -i ~/.ssh/dell_t710_key scraper@192.168.50.54

# Verificar configuraciÃ³n
cat config/ssh_config.json
```

#### 2. Scraper Bloqueado por Cloudflare
```
WARNING: PÃ¡gina bloqueada - detectado: #challenge-form
```
**SoluciÃ³n**:
- El sistema usa tÃ©cnicas anti-detecciÃ³n probadas
- Verificar que estÃ¡ usando el scraper hÃ­brido correcto
- Ajustar timing entre pÃ¡ginas
- Revisar User-Agent en configuraciÃ³n

#### 3. Alta UtilizaciÃ³n de Recursos
```
CRITICAL: CPU usage critical: 92.1%
```
**SoluciÃ³n**:
```bash
# Verificar scrapers activos
python monitoring/performance_monitor.py --status

# Reducir scrapers concurrentes
# Editar config/dell_t710_config.yaml:
# max_concurrent_scrapers: 2  # Reducir de 4 a 2
```

#### 4. Fallo en Checkpoint/RecuperaciÃ³n
```
ERROR: Error cargando checkpoint
```
**SoluciÃ³n**:
```bash
# Limpiar checkpoints corruptos
rm logs/checkpoints/*.pkl

# Reiniciar scraper desde pÃ¡gina especÃ­fica
python scrapers/inmuebles24_professional.py --resume=25 --pages=100
```

### ðŸ” Debugging Avanzado

#### Modo Debug con GUI:
```bash
# Ejecutar con interfaz grÃ¡fica para debugging
python scrapers/inmuebles24_professional.py --gui --pages=5
```

#### Logs detallados:
```bash
# Incrementar nivel de logging
# En el scraper, cambiar:
# logging.basicConfig(level=logging.DEBUG)
```

#### Monitoreo en tiempo real:
```bash
# SSH al servidor y monitorear
ssh scraper@192.168.50.54
htop  # Monitor de procesos
iotop # Monitor de I/O
```

### ðŸ“ž EscalaciÃ³n de Problemas

Si los problemas persisten:

1. **Recopilar informaciÃ³n**:
   ```bash
   # Generar reporte completo
   python monitoring/performance_monitor.py --report > problem_report.json
   
   # Recopilar logs recientes
   tar -czf logs_$(date +%Y%m%d).tar.gz logs/
   ```

2. **Verificar recursos del sistema**:
   ```bash
   python ssh_deployment/remote_executor.py --status
   ```

3. **Documentar**:
   - Timestamp del problema
   - Logs relevantes
   - ConfiguraciÃ³n utilizada
   - Pasos para reproducir

---

## ðŸ“š API y Referencias

### ðŸ”§ Clases Principales

#### `Inmuebles24ProfessionalScraper`
```python
scraper = Inmuebles24ProfessionalScraper(
    headless=True,           # Modo sin GUI
    max_pages=100,          # PÃ¡ginas mÃ¡ximas
    resume_from=1,          # PÃ¡gina de inicio
    operation_type='venta'  # 'venta' o 'renta'
)

results = scraper.run()
```

#### `ConcurrentScraperManager`
```python
manager = ConcurrentScraperManager(max_concurrent=4)

scraper_configs = [
    {
        'site': 'inmuebles24',
        'operation': 'venta',
        'headless': True,
        'max_pages': 100
    }
]

results = manager.run_batch_scraping(scraper_configs)
```

#### `DellT710SSHExecutor`
```python
with DellT710SSHExecutor() as executor:
    # Desplegar proyecto
    executor.deploy_project(project_root)
    
    # Ejecutar scraper remoto
    result = executor.execute_scraper('inmuebles24', {
        'headless': True,
        'max_pages': 50,
        'operation': 'venta'
    })
```

### ðŸ“‹ ConfiguraciÃ³n de ParÃ¡metros

#### Dell T710 Config (YAML):
```yaml
resource_limits:
  max_cpu_usage_percent: 80
  max_memory_usage_percent: 80
  max_concurrent_scrapers: 4

scraping_optimization:
  page_load_timeout: 30
  between_page_delay: 2
  checkpoint_interval: 50
```

#### Scraper Settings (JSON):
```json
{
  "inmuebles24": {
    "base_url": "https://www.inmuebles24.com/departamentos-en-{operation}-en-zapopan-jalisco.html",
    "selectors": {
      "property_cards": "div[data-qa='posting PROPERTY']",
      "title": "h2 a, h3 a",
      "price": ".price, .posting-price",
      "location": ".posting-location"
    }
  }
}
```

### ðŸ“Š Estructura de Datos de Salida

#### CSV Propiedades:
```csv
timestamp,operation_type,titulo,precio,ubicacion,caracteristicas,link
2025-08-29T14:30:00,venta,"Departamento en venta","$2,500,000","Zapopan, Jalisco","2 hab | 2 baÃ±os | 85mÂ²","https://..."
```

#### Metadata JSON:
```json
{
  "execution_info": {
    "timestamp": "20250829_143000",
    "operation_type": "venta",
    "total_pages_processed": 100,
    "total_properties_found": 2541,
    "execution_time_seconds": 7892.5
  },
  "system_info": {
    "scraper_version": "1.0.0",
    "headless_mode": true,
    "max_pages_limit": 100
  }
}
```

---

## ðŸŽ¯ Roadmap y Futuras Mejoras

### ðŸ“‹ PrÃ³ximas CaracterÃ­sticas

1. **MÃ¡s Sitios Web**:
   - Implementar scrapers para casasyterrenos.com
   - Agregar soporte para lamudi.com.mx
   - Desarrollar scraper de mitula.com.mx

2. **Mejoras de IA**:
   - DetecciÃ³n inteligente de layouts
   - AdaptaciÃ³n automÃ¡tica a cambios en sitios web
   - ClasificaciÃ³n automÃ¡tica de propiedades

3. **Analytics Avanzado**:
   - Dashboard web para monitoreo
   - AnÃ¡lisis de precios y tendencias
   - Reportes automatizados

4. **Escalabilidad**:
   - Soporte para mÃºltiples servidores
   - Balanceado de carga automÃ¡tico
   - Almacenamiento distribuido

### ðŸ”„ Mantenimiento Continuo

- **Updates mensuales** de dependencias
- **RevisiÃ³n trimestral** de selectores web
- **OptimizaciÃ³n semestral** de rendimiento
- **Backup anual** de configuraciones

---

**VersiÃ³n**: 1.0.0  
**Fecha**: Agosto 2025  
**Desarrollado para**: Dell PowerEdge T710 + Ubuntu Server 24  
**Control desde**: Windows 11 via SSH
