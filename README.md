# PropertyScraper Dell710 - Professional Web Scraping System

## ğŸ¯ DescripciÃ³n del Proyecto

Sistema profesional de web scraping diseÃ±ado especÃ­ficamente para el servidor Dell T710 con Ubuntu Server 24. Implementa scraping concurrente, resiliente y automatizado para mÃºltiples sitios web de bienes raÃ­ces con ejecuciÃ³n remota SSH desde Windows 11.

## ğŸ—ï¸ Arquitectura del Sistema

### Hardware Target
- **Servidor**: Dell PowerEdge T710 
- **CPU**: Intel Xeon E5620 (8 cores, 2.40GHz)
- **RAM**: 24GB DDR3 ECC
- **Storage**: RAID0-10 HDDs
- **OS**: Ubuntu Server 24 LTS
- **Network**: SSH access via 192.168.50.54

### Software Stack
- **Lenguaje**: Python 3.12+
- **Web Scraping**: SeleniumBase (proven Cloudflare bypass)
- **Orchestration**: Custom concurrent manager
- **Remote Execution**: SSH + Paramiko
- **Monitoring**: Real-time logging + progress tracking
- **Data Format**: CSV + JSON metadata

### Componentes Principales

| Componente | FunciÃ³n |
|------------|---------|
| `master_controller.py` | Control central SSH desde Windows |
| `auto_deploy_manager.py` | Despliegue automatizado del sistema |
| `advanced_orchestrator.py` | OrquestaciÃ³n concurrente de scrapers |
| `enhanced_scraps_registry.py` | Registro y seguimiento de ejecuciones |
| `checkpoint_recovery.py` | RecuperaciÃ³n tras interrupciones |
| `gdrive_backup_manager.py` | Backup automÃ¡tico a Google Drive |
| `system_setup.py` | VerificaciÃ³n completa del entorno |

## ğŸ“ Estructura del Proyecto

```
PropertyScraper-Dell710/
â”œâ”€â”€ scrapers/                 # Scrapers individuales por sitio web
â”‚   â”œâ”€â”€ inm24.py             # Inmuebles24 scraper
â”‚   â”œâ”€â”€ inm24_det.py         # Inmuebles24 detallado scraper
â”‚   â”œâ”€â”€ cyt.py               # Casas y Terrenos scraper
â”‚   â”œâ”€â”€ lam.py               # Lamudi scraper
â”‚   â”œâ”€â”€ lam_det.py           # Lamudi detallado scraper
â”‚   â”œâ”€â”€ mit.py               # Mitula scraper
â”‚   â”œâ”€â”€ prop.py              # Propiedades scraper
â”‚   â””â”€â”€ tro.py               # Trovit scraper
â”œâ”€â”€ orchestrator/             # Sistema de orquestaciÃ³n concurrente
â”‚   â”œâ”€â”€ advanced_orchestrator.py
â”‚   â”œâ”€â”€ bimonthly_scheduler.py
â”‚   â””â”€â”€ concurrent_manager.py
â”œâ”€â”€ utils/                    # Utilidades y herramientas
â”‚   â”œâ”€â”€ create_data_structure.py
â”‚   â”œâ”€â”€ checkpoint_recovery.py
â”‚   â”œâ”€â”€ gdrive_backup_manager.py
â”‚   â”œâ”€â”€ enhanced_scraps_registry.py
â”‚   â””â”€â”€ url_utils.py
â”œâ”€â”€ URLs/                    # Archivos de URLs por sitio (cyt_urls.csv, mit_urls.csv, ...)
â”œâ”€â”€ config/                   # Configuraciones del sistema
â”‚   â”œâ”€â”€ dell_t710_config.yaml
â”‚   â””â”€â”€ ssh_config.json
â”œâ”€â”€ monitoring/               # Sistema de monitoreo
â”‚   â””â”€â”€ performance_monitor.py
â”œâ”€â”€ logs/                     # Logs del sistema
â”œâ”€â”€ data/                     # Datos estructurados con nueva nomenclatura
â”‚   â”œâ”€â”€ inm24/               # Inmuebles24 data
â”‚   â”‚   â”œâ”€â”€ venta/          # OperaciÃ³n venta
â”‚   â”‚   â”œâ”€â”€ renta/          # OperaciÃ³n renta
â”‚   â”‚   â”œâ”€â”€ venta-d/        # Venta desarrollos
â”‚   â”‚   â””â”€â”€ venta-r/        # Venta remates
â”‚   â”œâ”€â”€ cyt/                 # Casas y Terrenos data
â”‚   â”œâ”€â”€ lam/                 # Lamudi data
â”‚   â”œâ”€â”€ mit/                 # Mitula data
â”‚   â”œâ”€â”€ prop/                # Propiedades data
â”‚   â””â”€â”€ tro/                 # Trovit data
â”œâ”€â”€ ssh_deployment/           # Scripts de despliegue SSH
â”‚   â””â”€â”€ remote_executor.py
â””â”€â”€ docs/                     # DocumentaciÃ³n completa
```

## ğŸš€ CaracterÃ­sticas Principales

### âœ… Resilencia y RecuperaciÃ³n
- **Checkpoint System**: Puntos de guardado cada 50 pÃ¡ginas
- **Auto-Resume**: ContinÃºa automÃ¡ticamente tras interrupciones
- **Error Recovery**: Manejo inteligente de errores de red/servidor
- **Power Outage Protection**: RecuperaciÃ³n tras apagados inesperados

### âš¡ Concurrencia Optimizada
- **Resource Management**: Utiliza 80% de recursos Dell T710 (6.4 cores)
- **Concurrent Scrapers**: Hasta 4 scrapers simultÃ¡neos por sitio
- **Load Balancing**: DistribuciÃ³n inteligente de carga
- **Memory Management**: Control de memoria para evitar OOM

### ğŸ•’ AutomatizaciÃ³n Bi-mensual
- **Scheduled Execution**: Cada 15 dÃ­as automÃ¡ticamente
- **Intelligent Timing**: Evita horas pico de los sitios web
- **Data Organization**: Estructura automÃ¡tica por fecha/ejecuciÃ³n
- **Result Sync**: SincronizaciÃ³n automÃ¡tica de resultados

### ğŸ”’ Cloudflare Bypass Probado
- **Hybrid Technique**: MÃ©todo probado con 98% Ã©xito
- **Headless Operation**: OperaciÃ³n sin GUI en servidor
- **Anti-Detection**: ConfiguraciÃ³n optimizada para evadir detecciÃ³n
- **Success Rate**: 2541 propiedades extraÃ­das exitosamente

## ğŸ¯ Sitios Web Objetivo

1. **inmuebles24.com** âœ… (Implementado y probado - `inm24.py`, `inm24_det.py`)
2. **casasyterrenos.com** âœ… (Implementado - `cyt.py`)
3. **lamudi.com.mx** âœ… (Implementado - `lam.py`, `lam_det.py`)
4. **mitula.com.mx** âœ… (Implementado - `mit.py`)
5. **propiedades.com** âœ… (Implementado - `prop.py`)
6. **trovit.com.mx** âœ… (Implementado - `tro.py`)

## ğŸ“Š OrganizaciÃ³n de Datos

### Nueva Estructura Optimizada
```
data/{scraper_abrev}/{operation_abrev}/{mesAÃ±o}/{script}/
```

### Nomenclatura de Scrapers
- **inm24**: Inmuebles24 general
- **inm24_det**: Inmuebles24 detallado  
- **cyt**: Casas y Terrenos
- **lam**: Lamudi general
- **lam_det**: Lamudi detallado
- **mit**: Mitula
- **prop**: Propiedades
- **tro**: Trovit

### Tipos de OperaciÃ³n
- **venta**: Venta general
- **renta**: Renta general
- **venta-d**: Venta desarrollos (solo Inmuebles24)
- **venta-r**: Venta remates (solo Inmuebles24)

### Archivos de URLs

Los archivos CSV en `URLs/` son la Ãºnica fuente de URLs del sistema. Los
scrapers y el orquestador inspeccionan automÃ¡ticamente todos los archivos en
esta carpeta, por lo que no se requieren rutas hardcodeadas ni nombres de
archivo especÃ­ficos. Cada CSV comparte las siguientes columnas:

```csv
PaginaWeb,Ciudad,Operacion,ProductoPaginaWeb,URL
casas_y_terrenos,Guadalajara,Rentar,Edificios,https://...
```

Notas de nomenclatura:

- `Operacion` sin tilde.
- Operaciones en minÃºsculas: `venta`, `renta`, `venta-d`, `venta-r`.
- `venta-d` y `venta-r` aplican solo para Inmuebles24 (desarrollos y remates).

### Ejemplo de Ruta Actualizada
```
data/inm24/venta/ago2025/1/
â”œâ”€â”€ inm24_venta_ago_2025_script_1.csv
â”œâ”€â”€ metadata_script_1.json
â””â”€â”€ execution_log_script_1.log
```

### ProgramaciÃ³n de Ejecuciones
- **1ra EjecuciÃ³n**: DÃ­a 1-2 de cada mes
- **2da EjecuciÃ³n**: DÃ­a 15-16 de cada mes
- **DuraciÃ³n Estimada**: 4-8 horas por sitio web completo
- **Total Propiedades**: 15,000+ por ejecuciÃ³n

## ğŸ–¥ï¸ EjecuciÃ³n SSH Remota

### Desde Windows 11 â†’ Dell T710 Ubuntu
```bash
# ConexiÃ³n SSH automatizada
ssh scraper@192.168.50.54

# EjecuciÃ³n de scraper especÃ­fico
python3 /home/scraper/PropertyScraper-Dell710/scrapers/inm24.py

# Monitoreo en tiempo real
tail -f /home/scraper/PropertyScraper-Dell710/logs/progress_monitor.log
```

## âš™ï¸ ConfiguraciÃ³n Dell T710

### Recursos Asignados
- **CPU Cores**: 6.4 cores (80% de 8 cores)
- **Memory**: 19.2GB (80% de 24GB)
- **Concurrent Scrapers**: 4 mÃ¡ximo
- **Disk I/O**: Optimizado para RAID0-10

### Monitoreo de Performance
- **CPU Usage**: MÃ¡ximo 80%
- **Memory Usage**: MÃ¡ximo 80%
- **Network**: Bandwidth monitoring
- **Temperature**: Thermal monitoring

## ğŸ“ Quick Start

1. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   # Opcional: dependencias de desarrollo y pruebas
   pip install -r dev-requirements.txt
   ```

2. **Crear estructura de datos**:
   ```bash
   python utils/create_data_structure.py
   ```

3. **Ejecutar scraper individual**:
   ```bash
   # Inmuebles24 general
   python scrapers/inm24.py --headless --pages=100

   # Casas y Terrenos
   python scrapers/cyt.py --headless --pages=50

   # Lamudi
   python scrapers/lam.py --headless --pages=75
   ```

4. **Ejecutar orquestaciÃ³n completa**:
   ```bash
   python orchestrator/advanced_orchestrator.py
   ```

5. **Programar ejecuciÃ³n bi-mensual**:
   ```bash
   python orchestrator/bimonthly_scheduler.py
   ```

6. **Revisar estado de los scraps**:
   ```bash
   python monitoring/scrap_status.py --pagina-web Mit --ciudad Gdl
   ```
   Muestra ejecuciones completadas (runs `01`/`02`), tareas en curso segÃºn
   `data/orchestrator_state.json` y tareas en cola. Se puede filtrar por
   `PaginaWeb` y `Ciudad` y ordenar la salida.

## ğŸ† Resultados Probados

### Test exitoso - Inmuebles24 (`inm24.py`)
- **PÃ¡ginas procesadas**: 100
- **Propiedades extraÃ­das**: 2,541
- **Ã‰xito rate**: 98%
- **Tiempo total**: ~3 horas
- **Modo**: Headless (sin GUI)

### Sistema completamente migrado
- **8 Scrapers**: Todos funcionales con nueva nomenclatura
- **SeleniumBase**: ConfiguraciÃ³n estandarizada y compatible
- **Estructura de datos**: Optimizada con abreviaciones
- **URLs/**: Carpeta con los CSV individuales; Ãºnica fuente de URLs del sistema.

---

**Desarrollado para**: Dell PowerEdge T710  
**Optimizado para**: Ubuntu Server 24  
**Control remoto**: SSH desde Windows 11  
**Frecuencia**: Bi-mensual (cada 15 dÃ­as)
